{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_set = [ ({'length':5, 'endswith':'a', 'has_z':False}, 1), ({'length':2, 'endswith':'b', 'has_z':True}, 1), \n",
    "             ({'length':3, 'endswith':'e', 'has_z':True}, 2), ({'length':4, 'endswith':'a', 'has_z':True}, 2) ]\n",
    "\n",
    "classifier = nltk.DecisionTreeClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if length == 2: return 1\n",
      "if length == 3: return 2\n",
      "if length == 4: return 2\n",
      "if length == 5: return 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classifier.pseudocode(depth=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, suppose that we wanted a rule to decide whether a given name belongs to a Forgeling or not. Forgelings tend to choose names based on nicknames or words that have sentimental meaning to them, such as \n",
    "\n",
    "* Adamant\n",
    "* Helm\n",
    "* Pillar\n",
    "* Rust\n",
    "\n",
    "On the other hand, humans and Nantangil tend to have names like\n",
    "\n",
    "* Aramil (human male)\n",
    "* Wilhye (human male)\n",
    "* Callie (human female)\n",
    "* Brytha (human female)\n",
    "\n",
    "We will use a learner, which takes in a set of __features__ about a given name and then predicts whether the name belongs to a forgeling or not. Our job is to pick good features which help it determine the answer correctly.\n",
    "\n",
    "Based on the above examples, we might guess that Forgeling names tend to be shorter. They also seem to have consonants for the last letter more often than human names, which tend to end in vowels. Let's create a function which extracts these two features from a given name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_name_features(name):\n",
    "    my_output = {'length': len(name),\n",
    "                'last_letter': name[-1] }\n",
    "\n",
    "    return my_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will __train__ our algorithm, which means that we give it a set of examples which are correctly labeled. The learner will use our function to get the features for each example and try to guess the rule which gives the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Forgeling', 'Forgeling', 'Forgeling', 'Forgeling', 'Forgeling', 'Forgeling', 'Forgeling', 'Forgeling', 'Forgeling', 'Forgeling', 'Forgeling', 'Forgeling', 'Forgeling', 'Forgeling', 'Forgeling', 'Forgeling', 'Forgeling', 'Forgeling', 'Forgeling', 'Forgeling', 'Forgeling', 'Forgeling', 'Forgeling', 'Forgeling', 'Forgeling', 'Forgeling', 'Forgeling', 'Forgeling', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human', 'Human']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "name_frame = pd.read_csv(\"../../code/names_df.csv\")\n",
    "\n",
    "names = name_frame[\"Name\"].values\n",
    "labels = name_frame[\"Race\"].values\n",
    "labels = map(lambda x: \"Human\" if x==\"Kalashi\" else x, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n=len(labels)\n",
    "labels = labels[n/2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_y = labels[:35]\n",
    "test_y = labels[35:]\n",
    "\n",
    "train_x = names[:35]\n",
    "test_x = names[35:len(test_y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_training = [ (get_name_features(name), train_y[index] ) for index, name in enumerate(train_x)]\n",
    "my_testing = [ (get_name_features(name), test_y[index] ) for index, name in enumerate(test_x)]\n",
    "\n",
    "classifier = nltk.DecisionTreeClassifier.train(my_training, depth_cutoff=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if length == 4: return 'Forgeling'\n",
      "if length == 5: return 'Forgeling'\n",
      "if length == 6: return 'Forgeling'\n",
      "if length == 7: return 'Human'\n",
      "if length == 8: return 'Human'\n",
      "if length == 9: return 'Human'\n",
      "if length == 10: return 'Human'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classifier.pseudocode(depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4264705882352941"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(classifier, my_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240\n"
     ]
    }
   ],
   "source": [
    "print len(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'warforged_names.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\cferko\\Documents\\GitHub\\eldritch\\code\\saryn_3_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m \u001b[0mforgeling_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhuman_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\cferko\\Documents\\GitHub\\eldritch\\code\\saryn_3_backend.py\u001b[0m in \u001b[0;36mget_names\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"warforged_names.txt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mforgeling_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mforgeling_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforgeling_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\\t\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\t\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'warforged_names.txt'"
     ]
    }
   ],
   "source": [
    "%run ../../code/saryn_3_backend.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if last_letter == 'a': return 'Human'\n",
      "if last_letter == 'b': return 'Forgeling'\n",
      "if last_letter == 'c': return 'Human'\n",
      "if last_letter == 'd': \n",
      "  if length == 3: return 'Forgeling'\n",
      "  if length == 4: return 'Forgeling'\n",
      "  if length == 5: return 'Forgeling'\n",
      "  if length == 6: return 'Human'\n",
      "  if length == 7: return 'Forgeling'\n",
      "  if length == 8: return 'Human'\n",
      "if last_letter == 'e': \n",
      "  if length == 3: return 'Forgeling'\n",
      "  if length == 4: return 'Forgeling'\n",
      "  if length == 5: return 'Forgeling'\n",
      "  if length == 6: return 'Forgeling'\n",
      "  if length == 7: return 'Forgeling'\n",
      "  if length == 8: return 'Human'\n",
      "  if length == 9: return 'Forgeling'\n",
      "  if length == 12: return 'Forgeling'\n",
      "if last_letter == 'g': \n",
      "  if length == 3: return 'Forgeling'\n",
      "  if length == 4: return 'Human'\n",
      "  if length == 5: return 'Forgeling'\n",
      "  if length == 6: return 'Forgeling'\n",
      "if last_letter == 'h': \n",
      "  if length == 3: return 'Forgeling'\n",
      "  if length == 4: return 'Forgeling'\n",
      "  if length == 5: return 'Forgeling'\n",
      "  if length == 6: return 'Human'\n",
      "  if length == 7: return 'Human'\n",
      "  if length == 8: return 'Human'\n",
      "  if length == 9: return 'Human'\n",
      "if last_letter == 'i': return 'Human'\n",
      "if last_letter == 'k': \n",
      "  if length == 3: return 'Human'\n",
      "  if length == 4: return 'Forgeling'\n",
      "  if length == 5: return 'Forgeling'\n",
      "  if length == 6: return 'Human'\n",
      "  if length == 7: return 'Human'\n",
      "  if length == 9: return 'Forgeling'\n",
      "if last_letter == 'l': \n",
      "  if length == 4: return 'Forgeling'\n",
      "  if length == 5: return 'Forgeling'\n",
      "  if length == 6: return 'Human'\n",
      "  if length == 7: return 'Human'\n",
      "  if length == 8: return 'Forgeling'\n",
      "if last_letter == 'm': \n",
      "  if length == 3: return 'Forgeling'\n",
      "  if length == 4: return 'Forgeling'\n",
      "  if length == 5: return 'Human'\n",
      "  if length == 6: return 'Forgeling'\n",
      "  if length == 7: return 'Human'\n",
      "  if length == 8: return 'Forgeling'\n",
      "if last_letter == 'n': \n",
      "  if length == 3: return 'Forgeling'\n",
      "  if length == 4: return 'Forgeling'\n",
      "  if length == 5: return 'Human'\n",
      "  if length == 6: return 'Human'\n",
      "  if length == 7: return 'Human'\n",
      "  if length == 8: return 'Human'\n",
      "  if length == 9: return 'Human'\n",
      "  if length == 10: return 'Forgeling'\n",
      "if last_letter == 'o': \n",
      "  if length == 4: return 'Forgeling'\n",
      "  if length == 5: return 'Human'\n",
      "if last_letter == 'p': return 'Forgeling'\n",
      "if last_letter == 'r': \n",
      "  if length == 3: return 'Human'\n",
      "  if length == 4: return 'Forgeling'\n",
      "  if length == 5: return 'Human'\n",
      "  if length == 6: return 'Forgeling'\n",
      "  if length == 7: return 'Forgeling'\n",
      "  if length == 9: return 'Forgeling'\n",
      "  if length == 11: return 'Forgeling'\n",
      "if last_letter == 's': \n",
      "  if length == 4: return 'Forgeling'\n",
      "  if length == 5: return 'Forgeling'\n",
      "  if length == 6: return 'Human'\n",
      "  if length == 7: return 'Human'\n",
      "  if length == 8: return 'Forgeling'\n",
      "  if length == 9: return 'Forgeling'\n",
      "  if length == 10: return 'Forgeling'\n",
      "if last_letter == 't': return 'Forgeling'\n",
      "if last_letter == 'u': return 'Human'\n",
      "if last_letter == 'w': return 'Forgeling'\n",
      "if last_letter == 'x': return 'Human'\n",
      "if last_letter == 'y': return 'Forgeling'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier, accuracy = train_function(get_name_features)\n",
    "print classifier.pseudocode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "def get_names():\n",
    "    f = open(\"../../code/warforged_names.txt\")\n",
    "    forgeling_names = f.read()\n",
    "    forgeling_names = forgeling_names.replace(\"\\n\", \"\\t\").split(\"\\t\")\n",
    "    f.close()\n",
    "    \n",
    "    name_frame = pd.read_csv(\"../../code/names_df.csv\")\n",
    "    human_names = list(name_frame[name_frame[\"Race\"]==\"Human\"][\"Name\"].values)\n",
    "    \n",
    "    \n",
    "    f2 = open(\"../../code/extra_human_names.txt\")\n",
    "    more_names = f2.read()\n",
    "    more_names = more_names.replace(\"\\n\", \" \").replace(r\"\\x\",\" \").split(\" \")\n",
    "    more_names = filter(lambda x: len(x)>1 , more_names)\n",
    "    more_names.remove('S\\xe9verin') ## Hack, can't figure out how to remove this\n",
    "    more_names += ['Severin']\n",
    "    f2.close()\n",
    "    \n",
    "    human_names += more_names\n",
    "    \n",
    "    return forgeling_names, human_names\n",
    "\n",
    "def train_function(feature_function):\n",
    "    global human_names, forgeling_names\n",
    "    \n",
    "    train_x = human_names[:200] + forgeling_names[:200]\n",
    "    train_y = [\"Human\"]*200 + [\"Forgeling\"]*200\n",
    "    \n",
    "    test_x = human_names[200:] + forgeling_names[200:]\n",
    "    test_y = [\"Human\"]*(len(human_names)-200) + [\"Forgeling\"]*(len(forgeling_names)-200)\n",
    "    \n",
    "    train_set = [ (feature_function(name), train_y[index] ) \n",
    "                for index, name in enumerate(train_x)]\n",
    "                    \n",
    "    test_set = [ (feature_function(name), test_y[index] ) \n",
    "                for index, name in enumerate(test_x)]\n",
    "                    \n",
    "    classifier = nltk.DecisionTreeClassifier.train(train_set)\n",
    "    accuracy = nltk.classify.accuracy(classifier, test_set)\n",
    "    \n",
    "    return classifier, accuracy\n",
    "    \n",
    "forgeling_names, human_names = get_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's your turn.\n",
    "\n",
    "__Challenge.__ Choose a set of features to train a classifier which will recognize whether a word is in the Common tongue or in Nan, the language of the Nantangil. Here is a poem written in the Nan language to give you a sense of what it looks like:\n",
    "\n",
    ">Tewti ma utral, tewti ma utral,\n",
    "\n",
    ">ngeyä ayrìk leiu lor!\n",
    "\n",
    ">nga krrmì tsawkeyä tsawl slu\n",
    "\n",
    ">sì fìkrrmì a vawm leru\n",
    "\n",
    ">Tewti ma utral, tewti ma utral,\n",
    "\n",
    ">ngeyä ayrìk leiu lor.\n",
    "\n",
    ">Tewti ma utral, tewti ma utral,\n",
    "\n",
    ">oel kameie ngati!\n",
    "\n",
    ">frazìsìt oeru sunu nga,\n",
    "\n",
    ">a zera'eiu Eywata!\n",
    "\n",
    ">Tewti ma utral, tewti ma utral,\n",
    "\n",
    ">oel kameie ngati!\n",
    "\n",
    ">Tewti ma utral, tewti ma utral,\n",
    "\n",
    ">ngal keiar oeru futa\n",
    "\n",
    ">meoauniaeal\n",
    "\n",
    ">frakrr awngati fmereial\n",
    "\n",
    ">Tewti ma utral, tewti ma utral,\n",
    "\n",
    ">ngal keiar oeru fì'ut.\n",
    "\n",
    "What features do you think are important for distinguishing between Nan and Common? You may choose as many features as you like, but including too many poor features (those that do not differ substantially between Nan and Common) will reduce the performance of your learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_langage_features(word):\n",
    "    ## Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you are ready, run the cell defining your function and checkpoint your progress. Your function will be used to train a learner and tested against a large collection of Nan and Common text. The better your learner does, the more influence will be awarded to House Saryn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "�\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
